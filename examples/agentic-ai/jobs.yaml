version: "1.0"

# Agentic AI and LLM Inference Examples
defaults:
  runtime: "python:3.11-ml"
  resources:
    max_memory: 4096
    max_cpu: 80

jobs:
  # Multi-agent system for collaborative problem solving
  multi-agent:
    description: "Run collaborative AI agents for problem solving"
    command: python3
    args:
      - "multi_agent_system.py"
    uploads:
      files:
        - "multi_agent_system.py"
        - "requirements.txt"
    volumes:
      - "agent-memory"
      - "agent-logs"
    resources:
      max_memory: 2048
      max_cpu: 75
    runtime: "python:3.11"

  # LLM inference server
  llm-inference:
    description: "Run local LLM inference with optimized settings"
    command: python3
    args:
      - "llm_inference.py"
      - "--model=gpt2"
      - "--max-tokens=512"
    uploads:
      files:
        - "llm_inference.py"
        - "requirements.txt"
    volumes:
      - "model-cache"
      - "inference-logs"
    resources:
      max_memory: 4096
      max_cpu: 80
    runtime: "python:3.11-ml"

  # RAG (Retrieval-Augmented Generation) system
  rag-system:
    description: "Document Q&A with retrieval-augmented generation"
    command: python3
    args:
      - "rag_system.py"
      - "--index-path=/volumes/rag-index"
      - "--model=sentence-transformers"
    uploads:
      files:
        - "rag_system.py"
        - "requirements.txt"
    volumes:
      - "rag-index"
      - "document-store"
      - "embeddings-cache"
    resources:
      max_memory: 4096
      max_cpu: 80
    runtime: "python:3.11-ml"

  # Distributed training across multiple jobs
  distributed-training:
    description: "Train models using distributed computing"
    command: python3
    args:
      - "distributed_training.py"
      - "--role=coordinator"
      - "--workers=4"
    uploads:
      files:
        - "distributed_training.py"
        - "requirements.txt"
    volumes:
      - "training-data"
      - "model-checkpoints"
      - "training-logs"
    resources:
      max_memory: 6144
      max_cpu: 75
    runtime: "python:3.11-ml"

  # Install dependencies for all demos
  setup-deps:
    description: "Install required Python packages for AI demos"
    command: bash
    args:
      - "-c"
      - |
        echo "Installing AI/ML dependencies..."
        pip install -r requirements.txt --target=/volumes/python-libs
        echo "Dependencies installed to persistent volume"
    uploads:
      files:
        - "requirements.txt"
    volumes:
      - "python-libs"
    resources:
      max_memory: 2048
      max_cpu: 50
    runtime: "python:3.11"

  # Run all demos in sequence
  run-all:
    description: "Execute all AI demos sequentially"
    command: bash
    args:
      - "run_demos.sh"
    uploads:
      files:
        - "run_demos.sh"
        - "multi_agent_system.py"
        - "llm_inference.py"
        - "rag_system.py"
        - "distributed_training.py"
        - "requirements.txt"
    volumes:
      - "agent-memory"
      - "model-cache"
      - "rag-index"
      - "training-data"
    resources:
      max_memory: 4096
      max_cpu: 80
    runtime: "python:3.11"